# Apache Flink Pyflink interface

Flink just so happens to allow us to write user Defined Functions that act on each message, utilising Python and the Apache Flink package.

The three examples here are really simply, aka just scratching the surface of whats possible.

Reading the sensors readings as we are from a set of sensors fitted to a device, aka a machine of some sort, located in a factory, comparing the readings to pre defined good/ok/bad swim lanes and if required based on intelligence packaged in the UDF raise an alarm... 

A second example, imagine a inbound financial transaction stream, in real time. with this you can profile the transactions against previous transactions and deduce a potential fraud score, which is immediately pushed back to the producer to either allow or deny the transaction.

## How To.

in devlab0/ directory

1. `make run` - give it a minute to settle down

2. `make deploy`

3. now change directory to the project root and create your python virtual environment. This can be done by executing `python3 -m venv ./venv`

4. Next we need to activate the virtual environment, execute `source venv/bin/activate`

5. Next we need to install the required python packages using `pip install -r requirements`.

6. You can now change into `<root>/app_iot1` and execute `./site1.sh` This will start our data generator for the first region, namely factories 101 and 104.

7. You can also in a second window, again in the root folder activate your python environment using `source venv/bin/activate`, followed now by changing into `<root>/app_iot2 `and executing `./site2.sh`. This will start a 2nd region (`South`) load generator.
   
8. At this point if you want to you can inspect the data generated by going into the Confluent Control Center (`localhost:9021`), navigate to Topics and click on either `factory_iot_north` or `factory_iot_south` and then selecting the Messages tab.

9. If all of this worked then we can start the 3 labs as per below.

### Lab 1

1. `make jm `- This will open our Flink Jobmanager container and place us at a terminal. 
2. Open `devlab0/flink_flat0.cmd` and copy/past the first or second command into the jobmanager terminal.
2. You can now navigate to your Flink console by opening a browser and going to `localhost:8083`, you should see the job running state.
3. You can now navigate to your Confluent console by opening a browser and going to `localhost:9021`, you can now navigate to Topics, you can select either `factory_iot_north_101` or `factory_iot_south_102` and then selecting the Messages tab.


### Lab 2

1. `make jm `- This will open our Flink Jobmanager container and place us at a terminal. 
2. Open `devlab0/pyFlink/flink_flat1.cmd` and copy/past the first command or second (dependent on which script in #6 nd #7 you ran above) into the jobmanager terminal.
3. You can now navigate to your Flink console by opening a browser and going to `localhost:8083`, you should see the job running state.3. 
4. You can also open Flink Sql by executing `make fsql` and line for line copy/pasting the contents of `devlab0/pyFlink/flink_flat1.sql`. After a wile you should be seeing the inserted records start streaming.


### Lab 3

As per above, but now for `devlab0/pyFlink/flink_flat2.cmd`, `devlab0/pyFlink/flink_flat2.py` & `devlab0/pyFlink/flink_flat2.sql`  

### Lab 4

As per above, but now for `devlab0/pyFlink/flink_flat3.cmd`, `devlab0/pyFlink/flink_flat3.py` & `devlab0/pyFlink/flink_flat3.sql`  

### Lab 5

As per above, but now for `devlab0/pyFlink/flink_avg1.cmd`, `devlab0/pyFlink/flink_avg1.py` & `devlab0/pyFlink/flink_avg1.sql`